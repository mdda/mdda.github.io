## See for helpful jekyll stuff : http://jekyllrb.com/docs/templates/
## https://github.com/dbtek/jekyll-bootstrap-3/

sudo dnf install ruby-devel

## Instead : Add a Gemfile... and ::
gem install bundler
bundle install 

#if Ruby upgraded, simplest to ```rm -rf ~/.gem``` otherwise endless search through updates...
#And then : 
bundle update

## Painful route :
#bundle update 
## Problems : nokogiri, posix_spawn_ext

bundle exec jekyll serve --watch --unpublished --future
bundle exec jekyll serve --watch --unpublished --future --incremental



git config user.name "Martin Andrews"
git config user.email GitHub@mdda.net


### http://jekyllbootstrap3.tk/preview/#/theme/Dbyll
## rake theme:install git="https://github.com/jekyll-bs3/dbyll"


git add assets/themes/dbyll
git add _includes/themes/dbyll
git add _layouts/*

git commit -a -m "Gravatar MD5 included in _config.yml"

git commit -a -m "Put useful content in index.md - for homepage"


## Within the ai-blog directory, move yyyy-mm/title-text.md to yyyy-mm-01-title-text.md 
find . -name "*.md" | perl -n -e 'chomp(my $a=$_); (my $b=$a)=~s{\./}{}; $b =~s{\/}{-01-}; system(qq(cp $a $b));'

## Fix up the contents of the files
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntype: ai-blog}{\ncategory: AI}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\nai-blog: \[index\]\n}{\n}' '{}' \;

find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntype: oss-blog}{\ncategory: OSS}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\noss-blog: \[index\]\n}{\n}' '{}' \;

find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n---\n.*?\={10,}\n}{\nlayout: post\nfrom_mdda_blog: true\n---\n{\% include JB/setup \%}\n\n}s' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n---\n.*?\#\#.*?\n}{\nlayout: post\nfrom_mdda_blog: true\n---\n{\% include JB/setup \%}\n\n}s' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntagline:}{\nsubtitle:}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntopics:}{\ntags:}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\npublic: yes\n}{\n}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ndraft: true\n}{\npublished: false\n}i' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\nauthor: admin\n}{\n}' '{}' \;

## Fix up the syntax highlighting - for those without a language
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n\`\`\`\s*(.*?)\n\`\`\`\n}{\n\{\% highlight bash \%\}\n$1\n\{\% endhighlight \%\}\n}gs' '{}' \;
## Fix up the syntax highlighting - for those with a language specified
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n\`\`\`(.*?)\n(.*?)\n\`\`\`\n}{\n\{\% highlight $1 \%\}\n$2\n\{\% endhighlight \%\}\n}gs' '{}' \;

# Move to the appropriate directory
mv *.md ../../AI/
mv *.md ../../OSS/


### Fix up pages
# https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet

## Move over images
# Can't find any (??)

## Todo : Nicer TAG pages
http://stackoverflow.com/questions/1408824/an-easy-way-to-support-tags-in-a-jekyll-blog
http://christianspecht.de/tags/#reporting-services
http://docs.shopify.com/themes/liquid-documentation/filters/additional-filters

## Todo : GitHub Follow Button
http://ghbtns.com/
https://help.github.com/articles/repository-metadata-on-github-pages


Make MathJax work (??)

## Useful pages while writing :
  http://jekyllrb.com/docs/pages/
  https://github.com/dbtek/jekyll-bootstrap-3/
  https://github.com/jekyll-bootstrap-3/dbyll
  http://getbootstrap.com/css/#overview-container
  http://fortawesome.github.io/Font-Awesome/icons/

  http://getbootstrap.com/css/
  https://github.com/Shopify/liquid/wiki/Liquid-for-Designers


## Helpful : myfile=_posts/AI/ETC
## Helpful : touch --date '1 minute ago' ${myfile}
## Helpful : git commit --date="`stat -c %y ${myfile}`" ${myfile} -m "Last minute update"



Want to do in-depth look at :
  2014/2015 NIPS:
    -- Looking through papers for something interesting to write about

  PCAnet (http://arxiv.org/abs/1404.3606)
    Definitely need to contact authors in SG! :: DEAD END - sigh!
    
  GoogleLeNet (http://arxiv.org/abs/1409.4842)
    Follow up :
      Lin-2014 "Network in Network" (http://arxiv.org/abs/1312.4400)
        Hmpf

  Rafai Papers :
    #1 Rafai 2011 "Contractive AutoEncoders - Explicit Invariance" (http://www.icml-2011.org/papers/455_icmlpaper.pdf)
      Need to look at code to judge changes required for non-normalized inputs (but range-bound outputs)
      Not clear whether sigmoid needs to be 'top-and-tailed' or could be one-sided (Relu)
      
    #2 Rafai 2011 "Manifold Tangent Classifier" (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_1240.pdf)
      This appears less applicable to pure step-wise unsupervised learning, since it requires accumulation of various bundles of tangents, and then 'hind-sight'
      
    #3 Bengio 2012 "Better Mixing via Deep Representations" ()
      Interesting : This is much more of a hypothesis/discussion paper
      It's not clear that some of their hypotheses are alternatives (as appears to be suggested once or twice).  So the lack of proof for (a) doesn't imply evidence for (b), etc
      
    Homepage (includes links to Theano code) : 
      http://www-etud.iro.umontreal.ca/~rifaisal/
        https://github.com/lisa-lab/DeepLearningTutorials/blob/master/code/cA.py
        The cA.py code looks useful for the EEG task - having a go!
          Investigate ::
            Meaning of "Reconstruction Cost" (should it be negative? == No)
            And whether Jacobian should ever be NaN...  == No
            :: NEED TO NORMALIZE INPUTS to [0,1] ...
            :: Actually log(z) doesn't produce useful im(z) scaling-wise,
                 likely to be better to use polar( log(1+|z|), theta(z) ).{re, im}
    
  NER :     
    R. Grishman. Information extraction: Capabilities and challenges. Technical report, NYU Dept. CS, 2012. (http://cs.nyu.edu/grishman/tarragona.pdf)
  
    Useful from a literature review point of view - and goes through all the steps of IE nicely.
    But seems to run out of steam abruptly, rather than give nice "Further Work" ideas, for instance
    
  
  Google KV : Check refs :
    NER 
      [16] R. Grishman. Information extraction: Capabilities and challenges. Technical report, NYU Dept. CS, 2012. (http://cs.nyu.edu/grishman/tarragona.pdf)
      [18] READ B. Hachey, W. Radford, J. Nothman, M. Honnibal, and J. Curran. Evaluating entity linking with wikipedia. Artificial Intelligence, 194:130â€“150, 2013.  (http://benhachey.info/pubs/hachey-aij12-evaluating.pdf)
    Distance Training : 
      [29]  M. Mintz, S. Bills, R. Snow, and D. Jurafksy. Distant supervision for relation extraction without labeled data. In Prof. Conf. Recent Advances in NLP, 2009.  (http://web.stanford.edu/~jurafsky/mintz.pdf)
    Clustering of entities 
      [27] READ T. Mikolov, K. Chen, G. Corrado, and J. Dean.  Efficient estimation of word representations in vector space. In ICLR, 2013. (http://arxiv.org/abs/1301.3781)
      
  Socher-Manning video presentation again :: 
    http://techtalks.tv/talks/deep-learning-for-nlp-without-magic-part-1/58414/
    http://nlp.stanford.edu/courses/NAACL2013/NAACL2013-Socher-Manning-DeepLearning.pdf  (downloaded)
    http://www.socher.org/index.php/Main/ParsingWithCompositionalVectorGrammars
    NN for NER :: http://nlp.stanford.edu/~socherr/pa4_ner.pdf
    
  Dropout
    Hinton, Srivastava, Krizhevsky, Sutskever &amp; Salakhutdinov - 2012 (http://arxiv.org/abs/1207.0580)
      Minor point : TIMIT shares some features with EEG task
    Several things being tested, besides drop-out :
      Weight constraints (/rebalancing) instead of penalties
      Dropping 20% of input pixels for MNIST (no other 'tricks' used)
    Similarity to random forest in terms of feature sampling  
    Excellent level of detail in describing model set-ups in the appendix
    Efficient batchwise dropout training using submatrices (2015)
      http://arxiv.org/pdf/1502.02478v1.pdf

  JPEG originators' keynote / paper / talk
    Contractive AutoEncoders : Rafai
      Standard RBMs (Hinton 2006) use transpose of Weights to project back, is this opposite of Harpur?
        http://stackoverflow.com/questions/20534237/deep-autoencoder-using-rbm
        http://www.cs.toronto.edu/~hinton/
        RBMs are different in that the feedback is biniarized (last step uses raw probability)
          But doesn't he do dropout later on to 'add back noise'?
        Isn't SEC 3.16 (p38 of PDF) the same as RBM learningTR (9) with contractive thingy added on?  (Hmmm- it's a suggestive link...)
        Isn't Harpur 4.15 (p63 of PDF) the same as ... (has minimised reconstruction built-in)?  (Hmmm- it's a suggestive link...)

  GloVe paper
    Follow up:
      Lebret and Collobert 2014 : HPCA?  :: Remi Lebret and Ronan Collobert. 2014. Word embeddings through Hellinger PCA. In EACL.
      
      Levy et al 2014 : PPMI (also alternative to cosine similarity) :: Omer Levy, Yoav Goldberg, and Israel Ramat-Gan. 2014. Linguistic regularities in sparse and explicit word representations. CoNLL-2014.


  Collobert deeper dive (http://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf)
    This seems to be 'outsider' work, but state-of-the-art and as uncoloured by linguistic knowledge as possible
    Klein and Manning (2002) realistic hierarchical unsupervised grammar
    Has good appendix with layer descriptions in it
    Later paper : http://ronan.collobert.com/pub/matos/2011_parsing_aistats.pdf
      Code for 2008 version : https://github.com/turian/neural-language-model
    SOURCE :: http://ronan.collobert.com/senna/
  


Idea : Put up LibreOffice Python plugin notes

GPU stuff
  https://github.com/BIDData/BIDMach/wiki
  http://nlp.cs.berkeley.edu/pubs/Hall-BergKirkpatrick-Canny-Klein_2014_GPUParser_paper.pdf
  http://on-demand.gputechconf.com/gtc/2014/presentations/S4811-extreme-machine-learning-with-gpus.pdf
  Theano scan : http://nbviewer.ipython.org/gist/triangleinequality/1350873eebea33973e41
  
http://www.scipy.org/install.html
http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb
http://ipython.org/ipython-doc/stable/notebook/notebook.html

Theano : 
  Theano implementation of SENNA NER network
    https://github.com/Fematich/nn_ner
  Deep Learning Tutorial : NLP/word-embedding
    http://deeplearning.net/tutorial/rnnslu.html
    
  (Multi-layer Hidden&ReLu + LogisticOutput) with ADAgrad 
    http://nbviewer.ipython.org/github/dawenl/deep_tagging/blob/master/code/deep_tagging.ipynb
    https://github.com/dawenl/deep_tagging

  nntools (now Lasagne?) (FF-NN focussed)
    https://github.com/benanne/Lasagne
   
  blocks : (More RNN-focussed)
    http://blocks.readthedocs.org/en/latest/
    
  http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/multilayer_perceptron/multilayer_perceptron.ipynb

Gelphi : Graph Data Visualization

CloudFoundry :: github.com/cf-platform-eng/cf-community-workshop
  Neo4j
  Redis
  Postgres MySQL
  Jenkins

https://help.github.com/articles/syncing-a-fork/
https://github.com/Kunena/Kunena-Forum/wiki/Create-a-new-branch-with-git-and-manage-branches

TODO :  Add reference to talk.js presentation on RedCatLabs.com (plus video link?)



Teclast P80 annoyances
-------------------------------------------
http://www.gearbest.com/tablet-pcs/pp_286683.html
https://chiandroid.wordpress.com/category/tablets/teclast/
http://www.aliexpress.com/item/Teclast-P80-3G-Phablet-8-inch-Quad-Core-Android-5-1intel-SoFIA-C3230-64bit-1280-800/32608814119.html?spm=2114.01010208.3.206.3nguKv&ws_ab_test=searchweb201556_7,searchweb201602_1_10037_10017_10021_507_10033_10022_10032_10009_10020_10008_10018_10019,searchweb201603_1&btsid=fbee6553-12a8-4e81-90e2-a9598519076c


http://www.baidu.com/baidu?word=p80+site%3Ateclast.com

http://forums.androidcentral.com/google-nexus-6/502930-phone-keeps-rebooting-optimizing-apps-what-did-i-do-lol-4.html

Reset your Android One to factory settings
  https://support.google.com/android-one/answer/6088915?hl=en

https://www.androidpit.com/how-to-factory-reset-android
http://www.droidviews.com/how-to-boot-android-devices-in-fastboot-download-bootloader-or-recovery-mode/
http://trendblog.net/fix-soft-bricked-android-device-first-aid-guide/
http://trendblog.net/hard-reboot-reset-android/

http://androidforums.com/threads/teclast-p80-tablet.908950/

http://www.chinaphonearena.com/forum/Thread-Teclast-P80-bricked

http://www.teclast.com/tools/pad/showtools.php

http://bbs.teclast.com/forum-93-1.html
  http://bbs.teclast.com/thread-392079-1-1.html
  http://bbs.teclast.com/thread-255945-1-1.html
  http://bbs.teclast.com/thread-510532-1-1.html
  http://bbs.teclast.com/thread-258622-1-2.html


http://techtablets.com/forum/topic/teclast-official-firmware-repository/


2015-12-14
  P80 3G (K3H5) Android 5.1 firmware download
  V1.05_20151204 (android5.1)
  
  "telecommunications"
    P80 3G (K3H5) -Android5.1-V1.05.rar
      http://pan.baidu.com/s/1kUj2cx5
      File size: 487.6M

  "netcom"
    P80 3G (K3H5)-Android5.1-V1.05.rar
      http://pan.baidu.com/s/1kUj2cx5
      Gives up at : 524.3 kB (524,288 bytes)    


http://eponvert.net/UPP.html
https://github.com/eponvert/upparse

2007 - Voting Experts
  http://www.cs.williams.edu/~heeringa/publications/voting-experts.pdf
2008 - Hierarchical Voting Experts
  http://www.ece.iastate.edu/~alexs/papers/ICDL_2008_HVE/ICDL_2008_HVE.pdf
2009 - Bootstrap Voting Experts
  https://pdfs.semanticscholar.org/8930/f3807eb8a08df9b62a25768d8f66a455f062.pdf
2011 - (ACL) An Improved MDL-Based Compression Algorithm for Unsupervised Word Segmentation
  http://www.aclweb.org/anthology/P/P13/P13-2.pdf#page=214
  2009 - Johnson and Goldwater : Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars  
    http://homepages.inf.ed.ac.uk/sgwater/papers/naacl09_johnson.pdf

Perhaps this could be learned as a RL game?  
  Where the reward signal is the compression ratio?
  Either RL or evolving the agent...
  
Source code for lots of stuff (~2009)
  https://code.google.com/archive/p/voting-experts/
  https://github.com/pkt/voting-experts
    These include all the Text Corpora!

  
  From : 2009 - Bootstrap Voting Experts
    All of the corpora introduced in Section 5 (Orwell's 1984, Chinese Gigaword, BR87) were included in the this evaluation.  
    Three additional literary texts were added, Mark Twain's The Adventures of Huckleberry Finn, 
    Friedrich Nietzsche's Also Sprach Zarathustra in the original German, Julius Caesar's Comentarii de Bello Gallico in the original Latin, 
    as well as an additional corpus from CHILDES, Bloom73 [Bloom, 1973], 
    and a collection of stories for young children by William S. Gray. 
    For one of these corpora, Also Sprach Zarathustra, MDL chose the best possible segmentation. 
    Overall, MDL was always able to recover more than 90% of the quality of the best segmentation.


    
2012 - Turning the pipeline into a loop: Iterated unsupervised dependency parsing and PoS induction
  http://homepages.inf.ed.ac.uk/sgwater/papers/naacl12wkshp_iterated.pdf
  
2010 - Two Decades of Unsupervised POS induction: How far have we come? (includes code references)
  http://homepages.inf.ed.ac.uk/sgwater/papers/emnlp10-20yrsPOS.pdf
  
  
Wowza TTS : 
  https://google.github.io/tacotron/
  https://arxiv.org/pdf/1703.10135.pdf
  
  
Podcasting idea :
  http://www.lazada.sg/audio-technica-atr2500-usb-cardioid-condenser-usb-microphone-10516993.html

  https://www.aliexpress.com/item/Brand-New-Black-Y-200-Microphone-Audio-Professional-9cm-x-9cm-x-11-5cm-Shock-Mount/32659934098.html
  https://www.aliexpress.com/item/NB-35-Professional-Adjustable-Metal-Suspension-Scissor-Arm-Microphone-Stand-Holder-for-Mounting-on-PC-Laptop/32429556071.html
  
  >>> 50.0/215.*87.0
  20.232558139534884


geany 1.31.1 fc26 = gtk2
geany 1.31.5 fc27 = gtk3 - which kills geanypy :-(


[andrewsm@simlim ~]$ rpm -qa | grep geany
geany-1.31-5.fc27.x86_64
geany-plugins-common-1.31-5.fc27.x86_64
geany-devel-1.31-5.fc27.x86_64
geany-libgeany-1.31-5.fc27.x86_64
[andrewsm@simlim ~]$ su
Password: 
[root@simlim andrewsm]# dnf remove geany
Dependencies resolved.
=======================================================================================================================================
 Package                                    Arch                    Version                            Repository                 Size
=======================================================================================================================================
Removing:
 geany                                      x86_64                  1.31-5.fc27                        @fedora                   8.9 M
Removing dependent packages:
 geany-devel                                x86_64                  1.31-5.fc27                        @fedora                   438 k
 geany-libgeany                             x86_64                  1.31-5.fc27                        @fedora                   2.7 M
 geany-plugins-common                       x86_64                  1.31-5.fc27                        @fedora                   1.2 M
 gtk3-devel                                 x86_64                  3.22.26-1.fc27                     @updates                   30 M
Removing unused dependencies:
 at-spi2-atk-devel                          x86_64                  2.26.1-1.fc27                      @updates                  1.5 k
 at-spi2-core-devel                         x86_64                  2.26.2-1.fc27                      @updates                  1.3 M
 cairo-gobject-devel                        x86_64                  1.15.8-1.fc27                      @fedora                   6.6 k
 dbus-devel                                 x86_64                  1:1.12.0-1.fc27                    @updates                  127 k
 libXdamage-devel                           x86_64                  1.1.4-11.fc27                      @fedora                   2.5 k
 libepoxy-devel                             x86_64                  1.4.3-3.fc27                       @fedora                   1.5 M
 libxkbcommon-devel                         x86_64                  0.7.1-5.fc27                       @fedora                   290 k
 mesa-libwayland-egl-devel                  x86_64                  17.2.4-2.fc27                      @updates                  225  
 vte3                                       x86_64                  0.36.5-5.fc27                      @fedora                   984 k
 wayland-devel                              x86_64                  1.14.0-1.fc27                      @fedora                   568 k
 wayland-protocols-devel                    noarch                  1.10-1.fc27                        @fedora                   293 k

Transaction Summary
=======================================================================================================================================
Remove  16 Packages

Freed space: 48 M
Is this ok [y/N]: 


[andrewsm@simlim ~]$ ssh andrewsm@anson
Last login: Sun Nov 19 22:35:59 2017 from 192.168.2.254
[andrewsm@anson ~]$ rpm -qa | grep geany
geany-1.31-1.fc26.x86_64
geany-libgeany-1.31-1.fc26.x86_64
geany-plugins-common-1.31-1.fc26.x86_64
geany-plugins-geanypy-1.31-1.fc26.x86_64
[andrewsm@anson ~]$ 


ftp://rpmfind.net/linux/fedora/linux/updates/26/x86_64/g/geany-1.31-1.fc26.x86_64.rpm
ftp://rpmfind.net/linux/fedora/linux/updates/26/x86_64/g/geany-libgeany-1.31-1.fc26.x86_64.rpm
ftp://rpmfind.net/linux/fedora/linux/updates/26/x86_64/g/geany-plugins-common-1.31-1.fc26.x86_64.rpm
ftp://rpmfind.net/linux/fedora/linux/updates/26/x86_64/g/geany-plugins-geanypy-1.31-1.fc26.x86_64.rpm

dnf localinstall geany*.rpm

[root@simlim geany]# rpm -qa | grep geany
geany-plugins-geanypy-1.31-1.fc26.x86_64
geany-libgeany-1.31-1.fc26.x86_64
geany-1.31-1.fc26.x86_64
geany-plugins-common-1.31-1.fc26.x86_64


But be careful : 
dnf update # wants to update the base geany install, which will implicitly 
## disable geany-plugins-geanypy

See : https://ask.fedoraproject.org/en/question/23741/how-do-i-make-the-software-updater-skipexclude-some-packages/ updated for ```dnf ```instead of ```yum```:

nano /etc/dnf/dnf.conf
#Append the following line under [main] section, enter:
exclude=geany*

