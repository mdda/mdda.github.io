## See for helpful jekyll stuff : http://jekyllrb.com/docs/templates/
## https://github.com/dbtek/jekyll-bootstrap-3/

sudo dnf install ruby-devel

## Instead : Add a Gemfile... and ::
gem install bundler
bundle install 

#if Ruby upgraded, simplest to ```rm -rf ~/.gem``` otherwise endless search through updates...
#And then : 
bundle update

## Painful route :
#bundle update 
## Problems : nokogiri, posix_spawn_ext

bundle exec jekyll serve --watch --unpublished --future



git config user.name "Martin Andrews"
git config user.email GitHub@mdda.net


### http://jekyllbootstrap3.tk/preview/#/theme/Dbyll
## rake theme:install git="https://github.com/jekyll-bs3/dbyll"


git add assets/themes/dbyll
git add _includes/themes/dbyll
git add _layouts/*

git commit -a -m "Gravatar MD5 included in _config.yml"

git commit -a -m "Put useful content in index.md - for homepage"


## Within the ai-blog directory, move yyyy-mm/title-text.md to yyyy-mm-01-title-text.md 
find . -name "*.md" | perl -n -e 'chomp(my $a=$_); (my $b=$a)=~s{\./}{}; $b =~s{\/}{-01-}; system(qq(cp $a $b));'

## Fix up the contents of the files
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntype: ai-blog}{\ncategory: AI}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\nai-blog: \[index\]\n}{\n}' '{}' \;

find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntype: oss-blog}{\ncategory: OSS}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\noss-blog: \[index\]\n}{\n}' '{}' \;

find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n---\n.*?\={10,}\n}{\nlayout: post\nfrom_mdda_blog: true\n---\n{\% include JB/setup \%}\n\n}s' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n---\n.*?\#\#.*?\n}{\nlayout: post\nfrom_mdda_blog: true\n---\n{\% include JB/setup \%}\n\n}s' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntagline:}{\nsubtitle:}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ntopics:}{\ntags:}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\npublic: yes\n}{\n}' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\ndraft: true\n}{\npublished: false\n}i' '{}' \;
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\nauthor: admin\n}{\n}' '{}' \;

## Fix up the syntax highlighting - for those without a language
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n\`\`\`\s*(.*?)\n\`\`\`\n}{\n\{\% highlight bash \%\}\n$1\n\{\% endhighlight \%\}\n}gs' '{}' \;
## Fix up the syntax highlighting - for those with a language specified
find . -name "20*.md" -exec perl -0777 -i -p -e 's{\n\`\`\`(.*?)\n(.*?)\n\`\`\`\n}{\n\{\% highlight $1 \%\}\n$2\n\{\% endhighlight \%\}\n}gs' '{}' \;

# Move to the appropriate directory
mv *.md ../../AI/
mv *.md ../../OSS/


### Fix up pages
# https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet

## Move over images
# Can't find any (??)

## Todo : Nicer TAG pages
http://stackoverflow.com/questions/1408824/an-easy-way-to-support-tags-in-a-jekyll-blog
http://christianspecht.de/tags/#reporting-services
http://docs.shopify.com/themes/liquid-documentation/filters/additional-filters

## Todo : GitHub Follow Button
http://ghbtns.com/
https://help.github.com/articles/repository-metadata-on-github-pages


Make MathJax work (??)

## Useful pages while writing :
  http://jekyllrb.com/docs/pages/
  https://github.com/dbtek/jekyll-bootstrap-3/
  https://github.com/jekyll-bootstrap-3/dbyll
  http://getbootstrap.com/css/#overview-container
  http://fortawesome.github.io/Font-Awesome/icons/

  http://getbootstrap.com/css/
  https://github.com/Shopify/liquid/wiki/Liquid-for-Designers


## Helpful : myfile=_posts/AI/ETC
## Helpful : touch --date '1 minute ago' ${myfile}
## Helpful : git commit --date="`stat -c %y ${myfile}`" ${myfile} -m "Last minute update"



Want to do in-depth look at :
  2014/2015 NIPS:
    -- Looking through papers for something interesting to write about

  PCAnet (http://arxiv.org/abs/1404.3606)
    Definitely need to contact authors in SG! :: DEAD END - sigh!
    
  GoogleLeNet (http://arxiv.org/abs/1409.4842)
    Follow up :
      Lin-2014 "Network in Network" (http://arxiv.org/abs/1312.4400)
        Hmpf

  Rafai Papers :
    #1 Rafai 2011 "Contractive AutoEncoders - Explicit Invariance" (http://www.icml-2011.org/papers/455_icmlpaper.pdf)
      Need to look at code to judge changes required for non-normalized inputs (but range-bound outputs)
      Not clear whether sigmoid needs to be 'top-and-tailed' or could be one-sided (Relu)
      
    #2 Rafai 2011 "Manifold Tangent Classifier" (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_1240.pdf)
      This appears less applicable to pure step-wise unsupervised learning, since it requires accumulation of various bundles of tangents, and then 'hind-sight'
      
    #3 Bengio 2012 "Better Mixing via Deep Representations" ()
      Interesting : This is much more of a hypothesis/discussion paper
      It's not clear that some of their hypotheses are alternatives (as appears to be suggested once or twice).  So the lack of proof for (a) doesn't imply evidence for (b), etc
      
    Homepage (includes links to Theano code) : 
      http://www-etud.iro.umontreal.ca/~rifaisal/
        https://github.com/lisa-lab/DeepLearningTutorials/blob/master/code/cA.py
        The cA.py code looks useful for the EEG task - having a go!
          Investigate ::
            Meaning of "Reconstruction Cost" (should it be negative? == No)
            And whether Jacobian should ever be NaN...  == No
            :: NEED TO NORMALIZE INPUTS to [0,1] ...
            :: Actually log(z) doesn't produce useful im(z) scaling-wise,
                 likely to be better to use polar( log(1+|z|), theta(z) ).{re, im}
    
  NER :     
    R. Grishman. Information extraction: Capabilities and challenges. Technical report, NYU Dept. CS, 2012. (http://cs.nyu.edu/grishman/tarragona.pdf)
  
    Useful from a literature review point of view - and goes through all the steps of IE nicely.
    But seems to run out of steam abruptly, rather than give nice "Further Work" ideas, for instance
    
  
  Google KV : Check refs :
    NER 
      [16] R. Grishman. Information extraction: Capabilities and challenges. Technical report, NYU Dept. CS, 2012. (http://cs.nyu.edu/grishman/tarragona.pdf)
      [18] READ B. Hachey, W. Radford, J. Nothman, M. Honnibal, and J. Curran. Evaluating entity linking with wikipedia. Artificial Intelligence, 194:130â€“150, 2013.  (http://benhachey.info/pubs/hachey-aij12-evaluating.pdf)
    Distance Training : 
      [29]  M. Mintz, S. Bills, R. Snow, and D. Jurafksy. Distant supervision for relation extraction without labeled data. In Prof. Conf. Recent Advances in NLP, 2009.  (http://web.stanford.edu/~jurafsky/mintz.pdf)
    Clustering of entities 
      [27] READ T. Mikolov, K. Chen, G. Corrado, and J. Dean.  Efficient estimation of word representations in vector space. In ICLR, 2013. (http://arxiv.org/abs/1301.3781)
      
  Socher-Manning video presentation again :: 
    http://techtalks.tv/talks/deep-learning-for-nlp-without-magic-part-1/58414/
    http://nlp.stanford.edu/courses/NAACL2013/NAACL2013-Socher-Manning-DeepLearning.pdf  (downloaded)
    http://www.socher.org/index.php/Main/ParsingWithCompositionalVectorGrammars
    NN for NER :: http://nlp.stanford.edu/~socherr/pa4_ner.pdf
    
  Dropout
    Hinton, Srivastava, Krizhevsky, Sutskever &amp; Salakhutdinov - 2012 (http://arxiv.org/abs/1207.0580)
      Minor point : TIMIT shares some features with EEG task
    Several things being tested, besides drop-out :
      Weight constraints (/rebalancing) instead of penalties
      Dropping 20% of input pixels for MNIST (no other 'tricks' used)
    Similarity to random forest in terms of feature sampling  
    Excellent level of detail in describing model set-ups in the appendix
    Efficient batchwise dropout training using submatrices (2015)
      http://arxiv.org/pdf/1502.02478v1.pdf

  JPEG originators' keynote / paper / talk
    Contractive AutoEncoders : Rafai
      Standard RBMs (Hinton 2006) use transpose of Weights to project back, is this opposite of Harpur?
        http://stackoverflow.com/questions/20534237/deep-autoencoder-using-rbm
        http://www.cs.toronto.edu/~hinton/
        RBMs are different in that the feedback is biniarized (last step uses raw probability)
          But doesn't he do dropout later on to 'add back noise'?
        Isn't SEC 3.16 (p38 of PDF) the same as RBM learningTR (9) with contractive thingy added on?  (Hmmm- it's a suggestive link...)
        Isn't Harpur 4.15 (p63 of PDF) the same as ... (has minimised reconstruction built-in)?  (Hmmm- it's a suggestive link...)

  GloVe paper
    Follow up:
      Lebret and Collobert 2014 : HPCA?  :: Remi Lebret and Ronan Collobert. 2014. Word embeddings through Hellinger PCA. In EACL.
      
      Levy et al 2014 : PPMI (also alternative to cosine similarity) :: Omer Levy, Yoav Goldberg, and Israel Ramat-Gan. 2014. Linguistic regularities in sparse and explicit word representations. CoNLL-2014.


  Collobert deeper dive (http://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf)
    This seems to be 'outsider' work, but state-of-the-art and as uncoloured by linguistic knowledge as possible
    Klein and Manning (2002) realistic hierarchical unsupervised grammar
    Has good appendix with layer descriptions in it
    Later paper : http://ronan.collobert.com/pub/matos/2011_parsing_aistats.pdf
      Code for 2008 version : https://github.com/turian/neural-language-model
    SOURCE :: http://ronan.collobert.com/senna/
  


Idea : Put up LibreOffice Python plugin notes

GPU stuff
  https://github.com/BIDData/BIDMach/wiki
  http://nlp.cs.berkeley.edu/pubs/Hall-BergKirkpatrick-Canny-Klein_2014_GPUParser_paper.pdf
  http://on-demand.gputechconf.com/gtc/2014/presentations/S4811-extreme-machine-learning-with-gpus.pdf
  Theano scan : http://nbviewer.ipython.org/gist/triangleinequality/1350873eebea33973e41
  
http://www.scipy.org/install.html
http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb
http://ipython.org/ipython-doc/stable/notebook/notebook.html

Theano : 
  Theano implementation of SENNA NER network
    https://github.com/Fematich/nn_ner
  Deep Learning Tutorial : NLP/word-embedding
    http://deeplearning.net/tutorial/rnnslu.html
    
  (Multi-layer Hidden&ReLu + LogisticOutput) with ADAgrad 
    http://nbviewer.ipython.org/github/dawenl/deep_tagging/blob/master/code/deep_tagging.ipynb
    https://github.com/dawenl/deep_tagging

  nntools (now Lasagne?) (FF-NN focussed)
    https://github.com/benanne/Lasagne
   
  blocks : (More RNN-focussed)
    http://blocks.readthedocs.org/en/latest/
    
  http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/multilayer_perceptron/multilayer_perceptron.ipynb

Gelphi : Graph Data Visualization

CloudFoundry :: github.com/cf-platform-eng/cf-community-workshop
  Neo4j
  Redis
  Postgres MySQL
  Jenkins

https://help.github.com/articles/syncing-a-fork/
https://github.com/Kunena/Kunena-Forum/wiki/Create-a-new-branch-with-git-and-manage-branches

TODO :  Add reference to talk.js presentation on RedCatLabs.com (plus video link?)



Teclast P80 annoyances
-------------------------------------------
http://www.gearbest.com/tablet-pcs/pp_286683.html
https://chiandroid.wordpress.com/category/tablets/teclast/
http://www.aliexpress.com/item/Teclast-P80-3G-Phablet-8-inch-Quad-Core-Android-5-1intel-SoFIA-C3230-64bit-1280-800/32608814119.html?spm=2114.01010208.3.206.3nguKv&ws_ab_test=searchweb201556_7,searchweb201602_1_10037_10017_10021_507_10033_10022_10032_10009_10020_10008_10018_10019,searchweb201603_1&btsid=fbee6553-12a8-4e81-90e2-a9598519076c


http://www.baidu.com/baidu?word=p80+site%3Ateclast.com

http://forums.androidcentral.com/google-nexus-6/502930-phone-keeps-rebooting-optimizing-apps-what-did-i-do-lol-4.html

Reset your Android One to factory settings
  https://support.google.com/android-one/answer/6088915?hl=en

https://www.androidpit.com/how-to-factory-reset-android
http://www.droidviews.com/how-to-boot-android-devices-in-fastboot-download-bootloader-or-recovery-mode/
http://trendblog.net/fix-soft-bricked-android-device-first-aid-guide/
http://trendblog.net/hard-reboot-reset-android/

http://androidforums.com/threads/teclast-p80-tablet.908950/

http://www.chinaphonearena.com/forum/Thread-Teclast-P80-bricked

http://www.teclast.com/tools/pad/showtools.php

http://bbs.teclast.com/forum-93-1.html
  http://bbs.teclast.com/thread-392079-1-1.html
  http://bbs.teclast.com/thread-255945-1-1.html
  http://bbs.teclast.com/thread-510532-1-1.html
  http://bbs.teclast.com/thread-258622-1-2.html


http://techtablets.com/forum/topic/teclast-official-firmware-repository/


2015-12-14
  P80 3G (K3H5) Android 5.1 firmware download
  V1.05_20151204 (android5.1)
  
  "telecommunications"
    P80 3G (K3H5) -Android5.1-V1.05.rar
      http://pan.baidu.com/s/1kUj2cx5
      File size: 487.6M

  "netcom"
    P80 3G (K3H5)-Android5.1-V1.05.rar
      http://pan.baidu.com/s/1kUj2cx5
      Gives up at : 524.3 kB (524,288 bytes)    


http://eponvert.net/UPP.html
https://github.com/eponvert/upparse

2007 - Voting Experts
  http://www.cs.williams.edu/~heeringa/publications/voting-experts.pdf
2008 - Hierarchical Voting Experts
  http://www.ece.iastate.edu/~alexs/papers/ICDL_2008_HVE/ICDL_2008_HVE.pdf
2009 - Bootstrap Voting Experts
  https://pdfs.semanticscholar.org/8930/f3807eb8a08df9b62a25768d8f66a455f062.pdf
2011 - (ACL) An Improved MDL-Based Compression Algorithm for Unsupervised Word Segmentation
  http://www.aclweb.org/anthology/P/P13/P13-2.pdf#page=214
2009 - Johnson and Goldwater : Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars  
    http://homepages.inf.ed.ac.uk/sgwater/papers/naacl09_johnson.pdf
    
