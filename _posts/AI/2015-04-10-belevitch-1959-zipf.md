---
layout: post
category: AI
title: On the Statistical Laws of Linguistic Distributions
tagline:  Paper 
date: 2015-04-10
tags: [Zipf,PowerLaw,NLP]
published: false
---
{% include JB/setup %}

{% include custom/paper_review %}


### Belevitch (1959)

Argument shows that rank proportional to frequency (to a power) is a 
characteristic of most roughly linear distributions.  


Perhaps truncated log-normal is an even better match to actual word frequencies, 
rather than defining distribution in terms of Zipf relationship.

i.e. fix up the distribution to be the tail of a log-normal distribution, and see what happens

But why use a tail?  Isn't there a distribution where the whole thing is relevant (exponential?)

    
* Statistics:
  + [Name distributions = ~Power Law](file:///home/andrewsm/Downloads/Statistical%20distribution%20of%20Chinese%20names.pdf)
  + [Least effort and the origins of scaling in human language](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC298679/)
  + [Zipf overview (2014)](http://colala.bcs.rochester.edu/papers/piantadosi2014zipfs.pdf)
