---
date: 2018-12-02
title:  "NIPS 2018"
tagline: Trip Notes
category: AI
tags:
- NIPS
layout: post
published: false
---
{% include JB/setup %}

```js
##  NIPS Authors

https://nips.cc/Conferences/2018/Schedule

//<div class="maincardBody">Visualization for Machine Learning</div>
//<div class="maincardFooter">J. Zico Kolter · Aleksander Madry</div>

var a=[], authors={}; $('div.maincard').each( function() { 
  var id=$(this).attr("id");
  var num = id.substr(-5);
  var title = $(this).find('.maincardBody').html();
  var names = $(this).find('.maincardFooter').html().split(' · ');
  names.forEach(n => {
    n=n.trim();
    authors[n] = (authors[n] || 0)+1;
  });
  a.push( { id:num, title:title, names:names } );
}); console.log( a.slice(0,5).map( e => e.names.join(', ')) ); 
// Now print out top 10 authors (exclude coffee breaks)
console.log( Object.keys(authors).sort( (a,b) => (authors[b]-authors[a]) ).slice(1,11).map( a => a+' - '+authors[a]) );
/*
"Josh Tenenbaum - 16"
"Sergey Levine - 12"
"Eric Xing - 10"
"Michael Jordan - 10"
"Yoshua Bengio - 9"
"Stefano Ermon - 8"
"Jiajun Wu - 8"
"Yee Whye Teh - 8"
"Francis Bach - 8"
"Honglak Lee - 8"
*/
console.log( Object.keys(authors).join('\t') ); // Copy to file : 3423 distinct authors
//   Unfortunately, Workshop paper authors are not captured...

var author_last = Object.keys(authors).reduce( (acc,a) => {
  acc[a]=a.substring(a.lastIndexOf(' '));
  return acc;
}, {});
console.log( Object.keys(authors).map( a => author_last[a],trim()+"&&"+a).join('\t') );
// In resulting 'copy-paste' : Replace '\t'->'\n', '&&'->'\n' Copy to speadsheet, sort
// Now big id,paper,authors dump
console.log( a.map( e => e.id+"&&"+e.title+"&&"+(e.names.join(', ')) ).join('\t') ); 
// In resulting 'copy-paste' : Replace '\t'->'\n', '&&'->'\n' Copy to speadsheet (new tab)

```

### Tuesday  

####  Morning 

Word Embedding Dim
* Look at ||E1.E1^T - E2.E2^T|| - rotation invariant measure
  - Interested in spectra of each square matrix

Unsupervised alignment of text + speech (including different languages)
* Speech2vec : Unsupervised embeddings on (word-split) groups of samples?  
  - CHECK
  - ? Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech
    + https://arxiv.org/abs/1803.08976? 
    + http://people.csail.mit.edu/andyyuan/docs/philips.speech2vec.slides.pdf
  - ? Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces
    + https://papers.nips.cc/paper/7965-unsupervised-cross-modal-alignment-of-speech-and-text-embedding-spaces
    + https://papers.nips.cc/paper/7965-unsupervised-cross-modal-alignment-of-speech-and-text-embedding-spaces.pdf


Diffusion maps for Textual Network Embedding

Auto-correct for code
*  seq2seq tends to produce generic outputs without huge training data
*  Instead do retrieval with fix-ups
  -  Has been done back in 90s, and recently Hayati-2017+ for dialog systems
*  Dual optimisation of retriever and editor v difficult
  -  Suppose we had an Oracle editor : Can train retrieval directly
  -  Von-Mises distribition has KL divergence of L2 on unit sphere...
*  Actually works (but performs worse than honed syntax-tree methods)


##### Posters

```
5 - GumBolt: Extending Gumbel trick to Boltzmann priors
11 - (OpenAI people) Glow: Generative Flow with Invertible 1x1 Convolutions
27 - Graphical Generative Adversarial Networks
33 - (Nvidia people) Video-to-Video Synthesis
46 - Moonshine: Distilling with Cheap Convolutions
48 - SplineNets: Continuous Neural Decision Graphs
56 - Knowledge Distillation by On-the-Fly Native Ensemble
80 - NUS! SLAYER: Spike Layer Error Reassignment in Time
88 - Relational recurrent neural networks
99 - Embedding Logical Queries on Knowledge Graphs
```

Upstairs :
```
105 - GLoMo: Unsupervised Learning of Transferable Relational Graphs
```


#### Afternoon

```
3:30

220CD - Neural Voice Cloning with a Few Samples
220CD - Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog
220CD - Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
220CD - Learning to Optimize Tensor Programs

3:50

220CD - Generalisation of structural knowledge in the hippocampal-entorhinal system
220E  - Neural Ordinary Differential Equations

4:05

220CD - Generalizing Tree Probability Estimation via Bayesian Networks

4:25

4:55

220E  - Hierarchical Graph Representation Learning with Differentiable Pooling
```



##### Posters

```
5:00

210#35 - Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN
210#62 - Learning Hierarchical Semantic Image Manipulation through Structured Representations
210#70 - (Who?) Searching for Efficient Multi-Scale Architectures for Dense Image Prediction
210#76 - Chain of Reasoning for Visual Question Answering
210#77 - Learning Conditioned Graph Structures for Interpretable Visual Question Answering
210#87 - (DeepMind) The challenge of realistic music generation: modelling raw audio at scale
210#88 - Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices
210#89 - (Google) Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
210#91 - Neural Voice Cloning with a Few Samples
```

Upstairs

```
517#108 - Training Deep Neural Networks with 8-bit Floating Point Numbers
517#130 - To Trust Or Not To Trust A Classifier
517#138 - The Price of Fair PCA: One Extra dimension
```


### Wednesday  

TODO : Watch morning RL keynote online

####  Morning 

* Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language
  - Background-preserving image adjustments
* Neighbourhood Consensus Networks
  - Purely conditioned on same-image vs different-image
* Visual Memory for Robust Path Following
  - Localisation even with scene changes

* Sanity Checks for Saliency Maps
  - "Explanations" don't change even with random networks
  - i.e. confirmation bias makes it seem like these methods work
  - So : need to do sanity checks

* A Probabilistic U-Net for Segmentation of Ambiguous Images
  - Can determine how likely various segmentations are

* Virtual Class Enhanced Discriminative Embedding Learning
  - Add extra softmax class to squash other classes into finer directions


##### Posters

```
210#3  - Parsimonious Bayesian deep networks
210#10 - Sparsified SGD with Memory
210#20 - Porcupine Neural Networks: Approximating Neural Network Landscapes
210#21 - Adding One Neuron Can Eliminate All Bad Local Minima
210#27 - PCA of high dimensional random walks with comparison to neural network training
210#32 - Deep Generative Models with Learnable Knowledge Constraints
210#52 - The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network
```

####  Afternoon

...


### Thursday  

####  Morning

```
210#98 - Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures
```

####  Afternoon

* Keynote : Designing Computer Systems for Software 2.0
  - TODO : DC Mocanu - ‎2018 Nature - Sparsity ~ O(layer width)


* Norm matters: efficient and accurate normalization schemes in deep networks
  - TODO : Read

* A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks
  - TODO : Read

* Oral : Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning
  - TODO : Read

* Learning to Infer Graphics Programs from Hand-Drawn Images
  - TODO : Read

* Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation
  - TODO : Read

* Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels
  - TODO : Read



### Friday : Workshops

* ViGIL



### Saturday : Workshops

MLOSS : Our talk : 11:20-11:40

```
513DEF :: 13:30-14:00 Ralf Schlüter, "Automatic Speech Recognition Architectures: from HMM to End-to-End Modeling" (Talk)  =AudioInterpretability
516A   :: 14:00-14:40 Ray Mooney, "Learning to Understand Natural Language Instructions through Human-Robot Dialog" (Invited Talk)  =LearningByInstruction

515A   :: 15:30-15:50 Yury KuratovYury Kuratov, "DeepPavlov: An Open Source Library for Conversational AI (Demo)."  =MLOSS
MISSED 511CF  :: 15:30-17:00 Duckie town =Competition

220E   :: 16:00	Nando de Freitas "to be announced, DeepMind" =MetaLearning

MISSED 510AC  :: 16:25 Jeff Dean =MLSys 
513DEF :: 17:00	Jason Eisner "Bi-LSTM-FST"
```
