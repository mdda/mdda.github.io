---
date: 2018-03-06
title: Introduction to CNNs (Speech Stamps)
tagline: Presentation
category: AI
tags:
- Presentation
- TensorFlow
- CNNs
- SpeechRecognition
layout: post
published: true
---
{% include JB/setup %}



### Presentation Link

Sam Witteveen and I started the TensorFlow and Deep Learning Singapore group on MeetUp back in February 2017, 
and the group has grown significantly over the last ~12 months.  However, that also means that
many of the people who have recently joined missed out on our early sessions.  So we're re-running
some of the earlier events as <strike>"Replay"</strike> "Back-to-Basics" events, 
hoping that new people will be able to 'catch up' and get more out of coming to the main graoup events.  

Our [second 'Back-to-Basics' Meeting](https://www.sginnovate.com/events/deep-learning-and-tensorflow-back-basics-cnns) 
was supported by SGInnovate, in their office on Carpenter St.

As in the original March talk last year, I presented an introduction to CNNs, 
which are typically presented as a vision solution, using MNIST as an example.  
However, my version has a bit of a twist : Instead of using visual digits,
I have created a spoken-word dataset (the digits 0 to 9, of course), and the
CNN is trained to recognise spectrograms of the audio - i.e. the CNN is doing voice recognition!

As an added bonus, there's also an 'animals' audio dataset, and the demo notebook
includes an illustration of transfer learning : Where animal names are learned 
solely by modeling the errors made by the network trained to recognise digits.  
Fortunately, during the demo, the transfer-learned model scored 4/4 on the test animal name examples (YMMV).

The source for the CNN 'Stamps' Speech Recognition model is available on 
<a href="https://github.com/mdda/deep-learning-workshop" target="_blank">GitHub</a> - if 
you have questions on the software, please leave an 'issue' there.


<a href="http://redcatlabs.com/2018-03-06_TFandDL_IntroToCNNs/" target="_blank">
![Presentation Screenshot]({{ site.url }}/assets/img/2018-03-06_TFandDL_IntroToCNNs_600x390.png)
</a>

If there are any questions about the presentation please ask below, 
or contact me using the details given on the slides themselves.

<a href="http://redcatlabs.com/2018-03-06_TFandDL_IntroToCNNs/#/5/2" target="_blank">
![Presentation Content Example]({{ site.url }}/assets/img/2018-03-06_TFandDL_IntroToCNNs_5-2_600x390.png)
</a>



PS:  And if you liked the content, please 'star' the <a href="https://github.com/mdda/deep-learning-workshop" target="_blank">Deep Learning Workshop</a> repo ::
<!-- From :: https://buttons.github.io/ -->
<!-- Place this tag where you want the button to render. -->
<span style="position:relative;top:5px;">
<a aria-label="Star mdda/deep-learning-workshop on GitHub" data-count-aria-label="# stargazers on GitHub" data-count-api="/repos/mdda/deep-learning-workshop#stargazers_count" data-count-href="/mdda/deep-learning-workshop/stargazers" data-icon="octicon-star" href="https://github.com/mdda/deep-learning-workshop" class="github-button">Star</a>
<!-- Place this tag right after the last button or just before your close body tag. -->
<script async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
</span>

